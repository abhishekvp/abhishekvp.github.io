<!DOCTYPE html>
<html lang="en">

<head>

    <meta charset="utf-8">
    <meta name="viewport" content="width=1024">
    <meta name="description" content="Homepage of Dr. Abhishek V. Potnis, PhD">
    <meta name="author" content="Dr. Abhishek V. Potnis, PhD">
    <link rel="icon" type="image/png" href="favicon.png">
    <link href='https://fonts.googleapis.com/css?family=Titillium+Web:400,600,400italic,600italic,300,300italic' rel='stylesheet' type='text/css'>
    <title>Dr. Abhishek V. Potnis, PhD | Homepage</title>

    <!-- Bootstrap core CSS -->
    <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Eczar&display=swap" rel="stylesheet">


    <script type="text/javascript" src="assets/js/hidebib.js"></script>

    <!-- Custom styles for this template -->
    <style>


.cards-wrapper {
  display: flex;
  justify-content: center;
}
.card img {
  max-width: 100%;
  max-height: 100%;
}
.card {
  margin: 0 0.5em;
  box-shadow: 2px 6px 8px 0 rgba(22, 22, 26, 0.18);
  border: none;
  border-radius: 0;
}
.carousel-inner {
  padding: 1em;
}
.carousel-control-prev,
.carousel-control-next {
  background-color: #504d4de0;
  width: 5% !important;
  height: 5vh;
  border-radius: 5%;
  top: 50% !important;
  transform: translateY(-50%);
}
@media (min-width: 768px) {
  .card img {
    height: 11em;
  }
}


    .navbar-brand {
      font-size: 30px !important;
      font-weight: 400;
      color: #000;
    }

    a.nav-link.active {

    font-weight: 700;

}

a.nav-link {

color: black !important;

}
.bg-dark a {
  color: rgba(255,255,255,.5);
}

a{
  color: #086dda;
}

        body {
            padding-top: 54px;
            position: relative;
            color:#000 !important;
        }

        @media (min-width: 992px) {
            body {
                padding-top: 56px;
            }
        }

        body,
        td,
        th {
            font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
            font-size: 20px;
            font-weight: 400;
        }



        @media (min-width: 1200px) {
            .container {
                max-width: 70%;
            }
        }

        #pTitle {
            font-size: 20px;
        }

        #conference,
        #brief-desc {
            font-style: italic;
        }

        .abstract {
            text-align: justify;
            padding: 10px;
        }

        .paper {
            padding-bottom: 30px;
        }

        #sharePaper {
            padding-bottom: 10px;
        }

        .clear {
            height: 50px;
        }

        h3 {
            padding-top: 20px;
            padding-bottom: 20px;

            font-weight: 600;
            font-size: 27px;
        }

        .row {
            padding-top: 50px;
        }

        #paperImg {
            float: left;
            padding-right: 25px;
            font-size: 12px;
            text-align: center;
            padding-top: 15px;
        }

        #pText {
            display: block;
        }

        .footer {
            width: 100%;
            color: rgba(0, 0, 0, .9);
            text-align: center;
            font-size: 18px;
        }

        ul {
            text-align: justify;
        }

        .profile {
          width:200px;
          /*height: 233px;*/
          margin-top:50px;
          box-shadow: 0 1px 3px rgba(0,0,0,0.12), 0 1px 2px rgba(0,0,0,0.24);
          transition: all 0.3s cubic-bezier(.25,.8,.25,1);
          border-radius: 100px;

        }

pre {
margin-top:5px;
border:1px solid #000;
}

.profile:hover {/*
  box-shadow: 0 14px 28px rgba(0,0,0,0.25), 0 10px 10px rgba(0,0,0,0.22);

  border-radius:20px;*/
}
    </style>

</head>

<body data-spy="scroll" data-target=".navbar" data-offset="50" onload="init();">

    <!-- Navigation -->
    <nav class="navbar navbar-expand-lg fixed-top" style="background-color:white; box-shadow: 0 2px 2px 0 rgba(0, 0, 0, 0.14), 0 1px 5px 0 rgba(0, 0, 0, 0.12), 0 3px 1px -2px rgba(0, 0, 0, 0.2);">
        <div class="container">

            <a class="navbar-brand" href="#about" style="font-family: 'Eczar';">Abhishek V. Potnis, Ph.D.</a>
		<button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
          <span class="navbar-toggler-icon"></span>
        </button>
            <div class="collapse navbar-collapse" id="navbarResponsive">
                <ul class="navbar-nav ml-auto">
                    <li class="nav-item ">
                        <a class="nav-link" id = "aboutInit" href="#about">About
              </a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="#research">Research</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="#projects">Projects</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="#acads">Academics</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="#myTalks">Talks</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="#achievements">Achievements</a>
                    </li>
                 <li class="nav-item">
                        <a class="nav-link" target="_blank" href="http://abhishekvp.github.io/blog">Blog</a>
                    </li>
                </ul>
            </div>
        </div>
    </nav>

    <!-- Page Content -->
    <div class="container">
        <div class="row" id="about">
            <div class="col-sm-3">
                <img src="assets/me.jpg" class="profile" id = "mypic"/>
            </div>
            <div class="col-sm-9" style="font-size:17px;"><br><br>
                <p style="text-align:justify;">Hello! Welcome to my website! I am currently a Researcher in the 
                  <a href="https://www.ornl.gov/node/79427" target="_blank">Geospatial Artificial Intelligence (GeoAI) group</a> at <a href="https://www.ornl.gov/" target="_blank">Oak Ridge National Laboratory (ORNL)</a>.
                </p><p style="text-align:justify;">At ORNL, I work on developing scalable machine learning driven geospatial image analytics workflows for humanitarian applications.
                  
                  
                  I earned my Doctoral Degree in Geoinformatics, under the supervision of <a href="http://www.csre.iitb.ac.in/~sdurbha/" target="_blank">Prof. Surya Durbha</a> in the <a href="https://www.geosysiot.in/" target="_blank">GeoComputational Systems Lab</a> at <a href="https://www.iitb.ac.in/" target="_blank">Indian Institute of Technology Bombay</a>. My research interests include Deep Learning for Computer Vision, Large-Scale Satellite Image Processing, Remote Sensing and GIS, High Performance Computing, Geospatial Knowledge Representation and Reasoning, Natural Language Processing,  and Internet Of Things. </i>My doctoral research explored the areas of Geospatial Semantics and Deep Learning for Satellite Image Processing, towards leveraging Knowledge Graphs for enhanced Scene Understanding of Remote Sensing Scenes.</p>

                <p style="text-align:justify;">As a part of the <a href="https://sites.google.com/view/summerofearthengine/home?authuser=0" target="_blank">Google Summer of Earth Engine 2019</a> Research Program, I worked on "Machine Learning based Mapping of Croplands with Google Earth Engine for Identifying Human-Wildlife Conflict Locations" with <a href="https://cwsindia.org/" target="_blank"> Centre for Wildlife Studies</a>. I have been a two-time <a target="_blank" href="https://summerofcode.withgoogle.com/">Google Summer of Code</a> student for the organizations - <a target="_blank" href="https://cesiumjs.org/">Cesium</a> in <a target="_blank" href="https://cesiumjs.org/demos/DataCurtains/">2015</a>, where I contributed to the <a href="https://github.com/nasa-gibs/data-curtains" target="_blank">NASA's Global Imagery Browse Services (GIBS)</a> by processing and visualizing 3-dimensional LiDAR data from the <a href="https://www-calipso.larc.nasa.gov/" target="_blank">CALIPSO</a> satellite; and <a target="_blank" href="https://liquidgalaxy.endpoint.com/">Liquid Galaxy</a> in <a target="_blank" href="https://cesiumjs.org/demos/LiquidGalaxy/">2016</a>, where I worked on enabling Cesium for a panoramic experience on the Liquid Galaxy hardware. Prior to joining IIT Bombay as a graduate student for my Masters and PhD, I completed my Bachelors in Computer Engineering from University of Mumbai. </p><p style="text-align:justify;">I am an open source enthusiast and have been a <a target="_blank" href="https://hg.mozilla.org/mozilla-central/log?rev=Abhishek+Potnis">code</a> contributor to <a target="_blank" href="https://www.mozilla.org/en-US/firefox/">Mozilla Firefox</a>. When not at my terminal or engrossed in a sci-fi novel, I enjoy travelling places, capturing and captioning the world through my <a href="https://www.flickr.com/photos/abhishek_potnis/albums" target="_blank">camera</a>.</p>
            </div>

        </div>
        <div class="row" style="margin-top:-40px; font-size:18px;">
            <div class="col-sm-12">

                <p style="text-align: center;"><a href="mailto:potnisav@ornl.gov">Email</a> | <a target='_blank' href="https://scholar.google.co.in/citations?user=azL4OG8AAAAJ&hl=en">Scholar</a> |  <a target='_blank' href="https://orcid.org/0000-0001-8168-857X">ORCID</a> | <a target='_blank' href="https://www.webofscience.com/wos/author/record/HCH-9681-2022">Web Of Science</a> | <a target='_blank' href="https://github.com/abhishekvp/">Github</a> | <a target="_blank" href="https://www.linkedin.com/in/abhishekpotnis">LinkedIn</a> | <a target="_blank" href="https://twitter.com/abhishek_potnis">Twitter </a>| <a target="_blank" href="https://www.flickr.com/photos/abhishek_potnis/albums"> Flickr</a></p>
            </div>

        </div>

        <div class="row" id="news">
            <h3>News</h3>
            <div class="col-sm-12" style="font-size:16px;">


                <div>
                    <ul>
                      <li>[April 2023] Participated with esteemed researchers in a Panel Discussion on "AI Beyond Engineering" at the IEEE HKN TechX Conference</li>
                      <li>[April 2022] Joined the GeoAI research group at Oak Ridge National Laboratory, USA as a Research Associate in Machine Learning</li>
                      <li>[February 2022] Delivered Invited Talk on "Knowledge Graphs driven Remote Sensing Scene Understanding" at <a href="http://www.wadla.in/#program" target="_blank">WADLA 2.0 (“International Research Workshop on Advances in Deep Learning and Applications)”</a> at Indian Institute of Information Technology (IIIT), Sri City, Chittoor sponsored by the Department of Science and Technology, Government of India .
                      <li>[December 2021] Delivered Invited Talk at <a href="https://www.ieeebombaygrss.org/past-events" target="_blank">IEEE GRSS sponsored Short-term Training Program on Computational Intelligence in Remote Sensing</a> at RAIT, Mumbai.
                      <li>[October 2021] Successfully defended my Ph.D. Thesis titled "Semantics Enabled Framework for Remote Sensing Scene Understanding and Multi-modal Rendering".</li>
                     

</ul>
<div id ="olderNews">
<a href="#/" onclick="toggleOlderNews();">Older News >>></a>
<ul id="olderNewsListItems" style="display:none;">
 <br>
 <li>[September 2021] Our paper titled - "<a href="https://authors.elsevier.com/c/1dixJ3I9x1fLGC" target="_blank">LidarCSNet: A Deep Convolutional Compressive Sensing Reconstruction Framework for 3D Airborne Lidar Point Cloud</a>" has been accepted for publication in the <a target="_blank" href="https://www.sciencedirect.com/journal/isprs-journal-of-photogrammetry-and-remote-sensing">ISPRS Journal of Photogrammetry and Remote Sensing</a>.</li>
                        <li>[April 2021]: Our work on "Deep Learning based Real-time Building Classification using UAV Imagery" has been selected to be presented at <a href="https://web.cvent.com/event/7a211707-5b33-4f32-af69-a881dd5c6047/summary" target="_blank">IEEE Stratus 2021</a>.</li>

                        <li>[March 2021]: Paper titled "<a href="https://igarss2021.com/view_paper.php?PaperNum=4273" target="_blank">Towards Visual Exploration of Semantically Enriched Remote Sensing Scene Knowledge Graphs (RSS-KGs)</a>" has been accepted at <a href="https://igarss2021.com/default.asp" target="_blank">IEEE Geoscience and Remote Sensing Symposium (IEEE IGARSS 2021)</a>.</li>
                        <li>[March 2021]: Our work on  "<a href="https://igarss2021.com/view_paper.php?PaperNum=4268" target="_blank">Towards Enabling Deep Learning Based Question-Answering for 3D LiDAR Point Clouds </a>" has been accepted at <a href="https://igarss2021.com/default.asp" target="_blank">IEEE Geoscience and Remote Sensing Symposium (IEEE IGARSS 2021)</a>.</li>

                         <li>[March 2021]: Paper titled "<a href="https://igarss2021.com/view_paper.php?PaperNum=4294" target="_blank">Real-time Embedded HPC Based Earthquake Damage Mapping Using 3D LiDAR Point Clouds </a>" has been accepted at <a href="https://igarss2021.com/default.asp" target="_blank">IEEE Geoscience and Remote Sensing Symposium (IEEE IGARSS 2021)</a>.</li>
                      <li>[January 2021]: Our <a href="https://doi.org/10.3390/ijgi10010032" target="_blank">work</a> on rendering Comprehensive Spatio-Contextual Grounded Natural Language Scene Descriptions from Remote Sensing Scenes, leveraging Knowledge Graphs, has been published in the Special Issue on <a href="https://www.mdpi.com/journal/ijgi/special_issues/geo_ai" target="_blank">"Geospatial Artifical Intelligence"</a>
in the <a href="https://www.mdpi.com/journal/ijgi" target="_blank">ISPRS International Journal of Geo-Information</a>.</li>
<li>[October 2020]: Delivered <a href="https://youtu.be/1tx5HbttnwQ?t=62" target="_blank">Lightning Talk</a> at Google's <a href="https://earthoutreachonair.withgoogle.com/events/geoforgood20" target="_blank">Geo For Good Summit 2020</a> on "Machine Learning based Multi-Class Segmentation of Urban Flood Remote Sensing Scenes with Google Earth Engine".</li>
<li>[April 2020]: Paper titled "Towards Natural Language Question Answering over Earth Observation Linked Data using Attention-based Neural Machine Translation" accepted in <a href="https://igarss2020.org/" target="_blank">IEEE Geoscience and Remote Sensing Symposium (IGARSS 2020)</a> as Oral Presentation.</li>
 <li>[April 2020]: Paper titled "Online Point Cloud Super Resolution Using Dictionary Learning For 3D Urban Perception" accepted in <a href="https://igarss2020.org/" target="_blank">IEEE Geoscience and Remote Sensing Symposium (IGARSS 2020)</a> as Oral Presentation.</li>
                        <li>[October 2019]: Paper on "Semantics-enabled Spatio-Temporal Modeling of Earth Observation Data: An application to Flood Monitoring" accepted in <a href="https://sigspatial2019.sigspatial.org/" target="_blank">ACM SIGSPATIAL</a> International Workshop on <a href="https://aric2019.com/" target="_blank">Advances in Resilient and Intelligent Cities (ARIC 2019)</a>.</li>
 <li>[September 2019]: Presented my work on "Machine Learning based Mapping of Croplands with Google Earth Engine" at the <a href="https://sites.google.com/earthoutreach.org/geoforgood19/home" target="_blank">Geo For Good Summit</a> at Google, Sunnyvale, CA, USA.</li>
<li>[August 2019]: Successfully completed the project "Machine Learning based Mapping of Croplands with Google Earth Engine for Identifying Human-Wildlife Conflict Locations" with <a href="https://cwsindia.org/" target="_blank"> Centre for Wildlife Studies</a> for the <a href="https://sites.google.com/view/summerofearthengine/home?authuser=0" target="_blank">Google Summer of Earth Engine</a> Research Program.</li>
  <li>[July 2019]: Invited Talk on "Flood Mapping with Google Earth Engine" at the <a href="https://www.youtube.com/watch?v=xUiE5tLkXhk" target="_blank">Community on Air Webinar</a> organized by the Google Earth Engine India Community. </li>

      <li>[April 2019]: Paper on "Multi-Class Segmentation of Urban Floods from Multispectral Imagery using Deep Learning" accepted in <a href="https://igarss2019.org/" target="_blank">IEEE Geoscience and Remote Sensing Symposium (IGARSS 2019)</a>.</li>
  
                </ul>
                </div>
</div>
            </div>

        </div>

        <div class="row" id="research">
            <h3>Research</h3>
            <div class="col-sm-12" style="font-size:17px;">

              <div class="paper" id="jp-01">
                  <span id="paperImg"><img src="assets/jp01.png" width="200px" height="130px" /></span>
                  <div id="pText">
                      <div id="pTitle"> Semantics-Driven Remote Sensing Scene Understanding Framework for Grounded Spatio-Contextual Scene Descriptions  </div>
                      <div id="authors"><b>Abhishek Potnis</b>, Surya Durbha, Rajat Shinde</div>
                      <div id="conference">Special Issue on <a href="" target="_blank">GeoAI</a> in <a href="https://www.mdpi.com/journal/ijgi" target="_blank">ISPRS International Journal of Geo-Information</a></div>
                      <div id="sharePaper"><a href="javascript:toggleblock('jp-01-abs')">abstract</a> | <a target="_blank" href="https://doi.org/10.3390/ijgi10010032">paper</a> | <a shape="rect" href="javascript:togglebib('jp-01')" class="togglebib">bibtex</a> | <a href="https://github.com/abhishekvp/Sem-RSSU" target="_blank">ontologies developed</a></div>
                      <div id="jp-01-abs" class="abstract">
                       Earth Observation data possess tremendous potential in understanding the dynamics of our planet. We propose the Semantics-driven Remote Sensing Scene Understanding (Sem-RSSU) framework for rendering comprehensive grounded spatio-contextual scene descriptions for enhanced situational awareness. To minimize the semantic gap for remote-sensing-scene understanding, the framework puts forward the transformation of scenes by using semantic-web technologies to Remote Sensing Scene Knowledge Graphs (RSS-KGs). The knowledge-graph representation of scenes has been formalized through the development of a Remote Sensing Scene Ontology(RSSO)—a core ontology for an inclusive remote-sensing-scene data product. The RSS-KGs are enriched both spatially and contextually, using a deductive reasoner, by mining for implicit spatio-contextual relationships between land-cover classes in the scenes. The Sem-RSSU, at its core, constitutes novel Ontology-driven Spatio-Contextual Triple Aggregation and realization algorithms to transform KGs to render grounded natural language scene descriptions. Considering the significance of scene understanding for informed decision-making from remote sensing scenes during a flood, we selected it as a test scenario, to demonstrate the utility of this framework. In that regard, a contextual domain knowledge encompassing Flood Scene Ontology (FSO) has been developed. Extensive experimental evaluations show promising results, further validating the efficacy of this framework.
</div>
<pre xml:space="preserve">
  @article{Potnis2021,
    doi = {10.3390/ijgi10010032},
    url = {https://doi.org/10.3390/ijgi10010032},
    year = {2021},
    month = jan,
    publisher = {{MDPI} {AG}},
    volume = {10},
    number = {1},
    pages = {32},
    author = {Abhishek V. Potnis and Surya S. Durbha and Rajat C. Shinde},
    title = {Semantics-Driven Remote Sensing Scene Understanding Framework for Grounded Spatio-Contextual Scene Descriptions},
    journal = {{ISPRS} International Journal of Geo-Information}
  }
</pre>


                  </div>
            </div>


    <div class="paper" id="jp-02">
                  <span id="paperImg"><img src="assets/jp02.png" width="200px" height="130px"  /></span>
                  <div id="pText">
                      <div id="pTitle"> LidarCSNet: A Deep Convolutional Compressive Sensing Reconstruction Framework for 3D Airborne Lidar Point Cloud   </div>
                      <div id="authors">Rajat Shinde, Surya Durbha, <b>Abhishek Potnis</b></div>
                      <div id="conference"><a href="https://www.journals.elsevier.com/isprs-journal-of-photogrammetry-and-remote-sensing" target="_blank">ISPRS Journal of Photogrammetry and Remote Sensing</a></div>
                      <div id="sharePaper"><a href="javascript:toggleblock('jp-02-abs')">abstract</a> | <a target="_blank" href="https://doi.org/10.1016/j.isprsjprs.2021.08.019">paper</a> | <a shape="rect" href="javascript:togglebib('jp-02')" class="togglebib">bibtex</a> </div>
                      <div id="jp-02-abs" class="abstract">
                       Lidar scanning is a widely used surveying and mapping technique ranging across remote-sensing applications involving topological, and topographical information. Typically, lidar point clouds, unlike images, lack inherent consistent structure and store redundant information thus requiring huge processing time. The Compressive Sensing (CS) framework leverages this property to generate sparse representations and accurately reconstructs the signals from very few linear, non-adaptive measurements. The reconstruction is based on valid assumptions on the following parameters- (1) sampling function governed by sampling ratio for generating samples, and (2) measurement function for sparsely representing the data in a low-dimensional subspace. In our work, we address the following motivating scientific questions- Is it possible to reconstruct dense point cloud data from a few sparse measurements? And, what could be the optimal limit for CS sampling ratio with respect to overall classification metrics? Our work proposes a novel Convolutional Neural Network based deep Compressive Sensing Network (named LidarCSNet) for generating sparse representations using publicly available 3D lidar point clouds of the Philippines. We have performed extensive evaluations for analysing the reconstruction for different sampling ratios {4%, 10%, 25%, 50% and 75%} and we observed that our proposed LidarCSNet reconstructed the 3D lidar point cloud with a maximum PSNR of 54.47 dB for a sampling ratio of 75%. We investigate the efficacy of our novel LidarCSNet framework with 3D airborne lidar point clouds for two domains - forests and urban envi­ ronment on the basis of Peak Signal to Noise Ratio, Haussdorf distance, Pearson Correlation Coefficient and Kolmogorov-Smirnov Test Statistic as evaluation metrics for 3D reconstruction. The results relevant to forests such as Canopy Height Model and 2D vertical profile are compared with the ground truth to investigate the robustness of the LidarCSNet framework. In the urban environment, we extend our work to propose two novel 3D lidar point cloud classification frameworks, LidarNet and LidarNet++, achieving maximum classification ac­ curacy of 90.6% as compared to other prominent lidar classification frameworks. The improved classification accuracy is attributed to ensemble-based learning on the proposed novel 3D feature stack and justifies the robustness of using our proposed LidarCSNet for near-perfect reconstruction followed by classification. We document our classification results for the original dataset along with the point clouds reconstructed by using LidarCSNet for five different measurement ratios - based on overall accuracy and mean Intersection over Union as evaluation metrics for 3D classification. It is envisaged that our proposed deep network based convolutional sparse coding approach for rapid lidar point cloud processing finds huge potential across vast applications, either as a plug-and-play (reconstruction) framework or as an end-to-end (reconstruction followed by classification) system for scalability.
</div>
<pre xml:space="preserve">
  @article{Shinde2021,
      doi = {10.1016/j.isprsjprs.2021.08.019},
      url = {https://doi.org/10.1016/j.isprsjprs.2021.08.019},
      year = {2021},
      month = aug,
      publisher = {Elsevier},
      volume = {180},
      pages = {313-334},
      author = {Rajat C. Shinde, Surya S. Durbha, Abhishek V. Potnis},
      title = {LidarCSNet: A Deep Convolutional Compressive Sensing Reconstruction Framework for 3D Airborne Lidar Point Cloud},
      journal = {{ISPRS Journal of Photogrammetry and Remote Sensing}}
</pre>


                  </div>
            </div>
            <div class="paper" id="igarss2021-1">
                <span id="paperImg"><img src="assets/visual-exploration.png" width="200px" height="130px" /></span>
                <div id="pText">
                    <div id="pTitle">Towards Visual Exploration of Semantically Enriched Remote Sensing Scene Knowledge Graphs (RSS-KGs) </div>
                    <div id="authors"><b>Abhishek Potnis</b>, Surya Durbha, Rajat Shinde, Pratyush Talreja</div>
                    <div id="conference">IEEE International Geoscience and Remote Sensing Symposium (IGARSS 2021) </div>
                    <div id="sharePaper"><a href="javascript:toggleblock('igarss-2021-1-abs')">abstract</a> | <a target="_blank" href="https://ieeexplore.ieee.org/abstract/document/9554836">paper</a> | <a shape="rect" href="javascript:togglebib('igarss2021-1')" class="togglebib">bibtex</a> | <a target="_blank" href="http://www.geosysiot.in/tools/rssKG-Explorer/">visual interface developed</a> </div>
                    <div id="igarss-2021-1-abs" class="abstract">
                      There has been an increase in the adoption of Linked Data and subsequently representing data in the form of knowledge graphs across a wide spectrum of domains. There has also been significant interest in the remote sensing community to publish Earth Observation data in the form of Linked Data.  As the geospatial Linked Data cloud on the internet grows, there arises a need for efficient methods of exploratory analysis of such information-rich geospatial knowledge graphs. Knowledge graph representation of remote sensing scenes has proved to add significant value for effective mining of implicit information in addition to seamless integration with other data sources. This work is geared towards visual exploration of semantically enriched Remote Sensing Scene Knowledge Graphs (RSS-KGs). In this paper, we propose and implement an interactive web-based interface to visually explore and interact with RSS-KGs using Cesium. The proposed interface seeks to visualize the knowledge graph in the form of nodes and edges, mapped over the remote sensing scene consisting of different land use land cover regions and their inferred characteristics in addition to their spatial relationships with one another. It is envisaged that visualization in the form of nodes and edges would aid in visually validating the spatial relations in the knowledge graph, thus enhancing the understanding of the geospatial knowledge graph from the end user perspective. We demonstrate the efficacy of the interface through the visual exploration of an enriched geospatial knowledge graph of a remote sensing scene captured during an urban flood event.
</div>
<pre xml:space="preserve">
@INPROCEEDINGS{9554836,
      author={Potnis, Abhishek V. and Durbha, Surya S. and Shinde, Rajat C. and Talreja, Pratyush V.},
      booktitle={2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS}, 
      title={Towards Visual Exploration Of Semantically Enriched Remote Sensing Scene Knowledge Graphs (RSS-KGs)}, 
      year={2021},
      pages={5783-5786},
      doi={10.1109/IGARSS47720.2021.9554836}}
</pre>



                </div>
            </div>
            
            
            
            
            
            <br>
                        <div class="paper" id="igarss2021-2">
                <span id="paperImg"><img src="assets/lidarqa.png" width="200px" height="130px" style="border:0.5px solid #000;"/></span>
                <div id="pText">
                    <div id="pTitle">Towards Enabling Deep Learning Based Question-Answering for 3D LiDAR Point Clouds </div>
                    <div id="authors"> Rajat Shinde, Surya Durbha, <b>Abhishek Potnis</b>, Pratyush Talreja, Gaganpreet Singh </div>
                    <div id="conference">IEEE International Geoscience and Remote Sensing Symposium (IGARSS 2021) </div>
                    <div id="sharePaper"><a href="javascript:toggleblock('igarss-2021-2-abs')">abstract</a> | <a target="_blank" href="https://ieeexplore.ieee.org/abstract/document/9553785">paper</a> | <a shape="rect" href="javascript:togglebib('igarss2021-2')" class="togglebib">bibtex</a>  </div>
                    <div id="igarss-2021-2-abs" class="abstract">
                      Remote sensing lidar point cloud dataset embeds inherent 3D topological, topographical and complex geometrical information which possess immense potential in applications involving machine-understandable 3D perception. The lidar point clouds are unstructured, unlike images, and hence are challenging to process. In our work, we are exploring the possibility of deep learning-based question-answering on the lidar 3D point clouds. We are proposing a deep CNN-RNN parallel architecture to learn lidar point cloud features and word embedding from the questions and fuse them to form a feature mapping for generating answers. We have restricted our experiments for the urban domain and present preliminary results of binary question-answering (yes/no) using the urban lidar point clouds based on the perplexity, edit distance, evaluation loss, and sequence accuracy as the performance metrics. Our proposed hypothesis of lidar question-answering is the first attempt, to the best of our knowledge, and we envisage that our novel work could be a foundation in using lidar point clouds for enhanced 3D perception in an urban environment. We envisage that our proposed lidar question-answering could be extended for machine comprehension-based applications such as rendering lidar scene descriptions and content-based 3D scene retrieval.
</div>
<pre xml:space="preserve">
@INPROCEEDINGS{9553785,  
      author={Shinde, Rajat C. and Durbha, Surya S and Potnis, Abhishek V. and Talreja, Pratyush and Singh, Gaganpreet},  
      booktitle={2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS},   
      title={Towards Enabling Deep Learning-Based Question-Answering for 3D Lidar Point Clouds},   
      year={2021},  
      pages={6936-6939},  
      doi={10.1109/IGARSS47720.2021.9553785}
    }
</pre>



                </div>
            </div>
            
            
            


<br>
   <div class="paper" id="igarss2021-3">
                <span id="paperImg"><img src="assets/prat21.png" width="200px" height="130px" style="border:1px solid #000;"/></span>
                <div id="pText">
                    <div id="pTitle">Real-Time Embedded HPC Based Earthquake Damage Mapping Using 3D LiDAR Point Clouds </div>
                    <div id="authors">  Pratyush Talreja, Surya Durbha, Rajat Shinde, <b>Abhishek Potnis</b>  </div>
                    <div id="conference">IEEE International Geoscience and Remote Sensing Symposium (IGARSS 2021) </div>
                    <div id="sharePaper"><a href="javascript:toggleblock('igarss-2021-3-abs')">abstract</a> | <a target="_blank" href="https://ieeexplore.ieee.org/abstract/document/9554481">paper</a> | <a shape="rect" href="javascript:togglebib('igarss2021-3')" class="togglebib">bibtex</a>  </div>
                    <div id="igarss-2021-3-abs" class="abstract">
                     In the early hours following the earthquake, supporting humanitarian actions like rescue operations and relief distribution is the primary objective of the rescue managers. The damage mapping can be performed using reliable data that can be obtained from high-resolution satellite imagery but obtaining satellite imagery can be challenging for some days post disaster due to revisit time. Considering the disaster response timing, Unmanned Aerial Vehicles (UAV) are used because ground transportation systems are ineffective due to road blockage. In this work, we make use of Light Detection and Ranging (LiDAR) 3D point cloud data obtained for Haiti Earthquake. The focus of our work is to develop and implement an approach for LiDAR data classification to enable Earthquake damage mapping and detection. This is obtained by running our deep learning network on NVIDIA Jetson Nano embedded supercomputing platform. This approach takes the advantage of embedded High-Performance computing and low power consumption capabilities of Jetson Nano which enhances the classification and promotes rapid response which is the key to manage post-disaster activities. Jetson Nano is a feasible option which provides a GPU architecture that is optimized for running energy-aware deep learning models and which generates the results in real or near-real time. We envisage that our work could be extended to perform near real-time classification of LiDAR point clouds in a post earthquake scenario.
</div>
<pre xml:space="preserve">
@INPROCEEDINGS{9554481,
      author={Talreja, Pratyush and Durbha, Surya S and Shinde, Rajat C. and Potnis, Abhishek V.},
      booktitle={2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS}, 
      title={Real-Time Embedded HPC Based Earthquake Damage Mapping Using 3D LiDAR Point Clouds}, 
      year={2021},
      volume={},
      number={},
      pages={8241-8244},
      doi={10.1109/IGARSS47720.2021.9554481}
    }
</pre>



                </div>
            </div>
            
            








              <div class="paper" id="igarss2020-1">
                  <span id="paperImg"><img src="assets/nmt.png" width="200px" height="130px" /></span>
                  <div id="pText">
                      <div id="pTitle">Towards Natural Language Question Answering over Earth Observation Linked Data using Attention-based Neural Machine Translation </div>
                      <div id="authors"><b>Abhishek Potnis</b>, Rajat Shinde, Surya Durbha</div>
                      <div id="conference">IEEE International Geoscience and Remote Sensing Symposium (IGARSS 2020)</div>
                      <div id="sharePaper"><a href="javascript:toggleblock('igarss-2020-1-abs')">abstract</a> | <a target="_blank" href="https://arxiv.org/abs/2101.09427">arXiv</a> |  <a target="_blank" href="https://ieeexplore.ieee.org/document/9323183">paper</a> | <a shape="rect" href="javascript:togglebib('igarss2020-1')" class="togglebib">bibtex</a></div>
                      <div id="igarss-2020-1-abs" class="abstract">
                        With an increase in Geospatial Linked Open Data being adopted and published over the web, there is a need to develop intuitive interfaces and systems for seamless and efficient exploratory analysis of such rich heterogeneous multi-modal datasets. This work is geared towards improving the exploration process of Earth Observation (EO) Linked Data by developing a natural language interface to facilitate querying. Questions asked over Earth Observation Linked Data have an inherent spatio-temporal dimension and can be represented using GeoSPARQL. This paper seeks to study and analyze the use of RNN-based neural machine translation with attention for transforming natural language questions into GeoSPARQL queries. Specifically, it aims to assess the feasibility of a neural approach for identifying and mapping spatial predicates in natural language to GeoSPARQL’s topology vocabulary extension including - Egenhofer and RCC8 relations. The queries can then be executed over a triple store to yield answers for the natural language questions. A dataset consisting of mappings from natural language questions to GeoSPARQL queries over the Corine Land Cover(CLC) Linked Data has been created to train and validate the deep neural network. From our experiments, it is evident that neural machine translation with attention is a promising approach for the task of translating spatial predicates in natural language questions to GeoSPARQL queries.
</div>
<pre xml:space="preserve">
    @INPROCEEDINGS{9323183,
      author={A. V. {Potnis} and R. C. {Shinde} and S. S. {Durbha}},
      booktitle={IGARSS 2020 - 2020 IEEE International Geoscience and Remote Sensing Symposium},
      title={Towards Natural Language Question Answering Over Earth Observation Linked Data Using Attention-Based Neural Machine Translation},
      year={2020},
      volume={},
      number={},
      pages={577-580},
      doi={10.1109/IGARSS39084.2020.9323183}}
</pre>


                  </div>
              </div>
              <div class="paper" id="igarss2020-2">
                  <span id="paperImg"><img src="assets/cs.png" width="200px" style="border:1px solid #000;"/></span>
                  <div id="pText">
                      <div id="pTitle">Online Point Cloud Super Resolution Using Dictionary Learning For 3D Urban Perception </div>
                      <div id="authors">Rajat Shinde, <b>Abhishek Potnis</b>, Surya Durbha</div>
                      <div id="conference">IEEE International Geoscience and Remote Sensing Symposium (IGARSS 2020)</div>
                      <div id="sharePaper"> <a href="javascript:toggleblock('igarss-2020-2-abs')">abstract</a> | <a target="_blank" href="https://ieeexplore.ieee.org/document/9323992">paper</a> | <a shape="rect" href="javascript:togglebib('igarss2020-2')" class="togglebib">bibtex</a></div>
                      <div id="igarss-2020-2-abs" class="abstract">
                        Real-time embedded vision tasks require extraction of complex geometric and morphological features from the raw 3D point cloud acquired using range scanning systems like lidar, radar etc. and depth cameras. Such applications are found in autonomous navigation, surveying, 3D mapping and localization tasks such as automatic target recognition (ATR). Typically, a dataset acquired during surveying by remote sensing lidar scanners, known as point cloud, is (1) huge in size and requires a big chunk of memory for processing at a single instance and, (2) experiences missing information due to rapid change in orientation of the sensor while scanning. In our work, we are addressing both the issues combinedly by proposing an online point cloud super-resolution approach for translating a low dimensional point cloud to a high dimensional dense point cloud by learning dictionaries in the low-dimensional subspace. We are presenting our approach for an urban road scenario by reconstructing dense point clouds of 3D objects and comparing results based on PSNR and Hausdorff distance.

</div>

<pre xml:space="preserve">
    @INPROCEEDINGS{9323992,
      author={R. C. {Shinde} and A. V. {Potnis} and S. S. {Durbha}},
      booktitle={IGARSS 2020 - 2020 IEEE International Geoscience and Remote Sensing Symposium},
      title={Online Point Cloud Super Resolution using Dictionary Learning for 3D Urban Perception},
      year={2020},
      volume={},
      number={},
      pages={4414-4417},
      doi={10.1109/IGARSS39084.2020.9323992}}
</pre>

                  </div>
              </div>
              <div class="paper" id="acm-sigspatial-1">
                  <span id="paperImg"><img src="assets/acm-sigspatial1.png" width="200px" style="border:1px solid #000;"/></span>
                  <div id="pText">
                      <div id="pTitle">Semantics-enabled Spatio-Temporal Modeling of Earth Observation Data: An application to Flood Monitoring </div>
                      <div id="authors">Kuldeep Kurte, <b>Abhishek Potnis</b>, Surya Durbha</div>
                      <div id="conference">ACM SIGSPATIAL International Workshop on Advances on Resilient and Intelligent Cities(ARIC 2019), USA</div>
                      <div id="sharePaper"><a href="javascript:toggleblock('acm-sigspatial-1-abs')">abstract</a> | <a target="_blank" href="https://dl.acm.org/citation.cfm?id=3365545">paper</a> | <a shape="rect" href="javascript:togglebib('acm-sigspatial-1')" class="togglebib">bibtex</a></div>
                      <div id="acm-sigspatial-1-abs" class="abstract">
Extreme events such as urban floods are dynamic in nature, i.e. they evolve with time. The spatiotemporal analysis of such disastrous events is important for understanding the resiliency of an urban system during these events. Remote Sensing (RS) data is one of the crucial earth observation (EO) data sources that can facilitate such spatiotemporal analysis due to its wide spatial coverage and high temporal availability. In this paper, we propose a discrete mereotopology (DM) based approach to enable representation and querying of spatiotemporal information from a series of multitemporal RS images that are acquired during a flood disaster event. We represent this spatiotemporal information using a semantic model called Dynamic Flood Ontology (DFO). To establish the effectiveness and applicability of the proposed approach, spatiotemporal queries relevant during an urban flood scenario such as, show me road segments that were partially flooded during the time interval t1 have been demonstrated with promising results.
</div>
<pre xml:space="preserve">
@inproceedings{Kurte:2019:SSM:3356395.3365545,
 author = {Kurte, Kuldeep and Potnis, Abhishek and Durbha, Surya},
 title = {Semantics-enabled Spatio-Temporal Modeling of Earth Observation Data: An Application to Flood Monitoring},
 booktitle = {Proceedings of the 2Nd ACM SIGSPATIAL International Workshop on Advances on Resilient and Intelligent Cities},
 series = {ARIC'19},
 year = {2019},
 isbn = {978-1-4503-6954-1},
 location = {Chicago, IL, USA},
 pages = {41--50},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/3356395.3365545},
 doi = {10.1145/3356395.3365545},
 acmid = {3365545},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {discrete mereotopology, flood disaster, ontology, semantics, spatial relations, spatiotemporal},
}
</pre>


                  </div>
              </div>


              <div class="paper" id="igarss19-1">
                  <span id="paperImg"><img src="assets/igarss-2019-1.png" width="200px" style="border:1px solid #000;"/></span>
                  <div id="pText">
                      <div id="pTitle">Multi-Class Segmentation of Urban Floods from Multispectral Imagery using Deep Learning</div>
                      <div id="authors"><b>Abhishek Potnis</b>, Rajat Shinde, Surya Durbha, Kuldeep Kurte</div>
                      <div id="conference">IEEE International Geoscience and Remote Sensing Symposium (IGARSS 2019), Japan</div>
                      <div id="sharePaper"><a href="javascript:toggleblock('igarss19-1-abs')">abstract</a> | <a target="_blank" href="https://ieeexplore.ieee.org/abstract/document/8900250/">paper</a> | <a shape="rect" href="javascript:togglebib('igarss19-1')" class="togglebib">bibtex</a></div>
                      <div id="igarss19-1-abs" class="abstract">Natural disasters such as floods, earthquakes, hurricanes, etc. have a huge impact on a society—causing destruction of life and property in their wake. During disasters such as flood, it is crucial to understand the dynamics of the situation as it occurs for effective response. In this paper, we address the problem of satellite image classification for urban floods using deep learning. We propose an encoder-decoder neural network based on the Efficient Residual Factorized Convnet(ERFNet), for multi-class segmentation of urban floods from multi-spectral satellite imagery. The ERFNet architecture capitalizes on skip connections and one dimensional convolutions to achieve the best possible trade-off between accuracy and efficiency. Since time is of essence during a disaster, the choice of the ERFNet architecture on a high performance computing (HPC) platform is apt. Satellite imagery from WorldView-2 of floods in Srinagar, India during September 2014 have been used for this study. The tool ‘markGT’ has been developed to assist end-to-end annotation of satellite imagery. The urban flood dataset used for this study has been generated using markGT. The proposed deep learning model over urban flood satellite imagery gives promising results on Nvidia Tesla K80 GPU. We envisage that the proposed model could be extended and improved for real-time classification of urban floods, thereby aiding disaster response personnel in making informed decisions.</div>

                      <pre xml:space="preserve">
                        @INPROCEEDINGS{8900250,
                        author={A. V. {Potnis} and R. C. {Shinde} and S. S. {Durbha} and K. R. {Kurte}},
                        booktitle={IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium},
                        title={Multi-Class Segmentation of Urban Floods from Multispectral Imagery Using Deep Learning},
                        year={2019},
                        volume={},
                        number={},
                        pages={9741-9744},
                        keywords={segmentation;flood;multi-class;classification;neural networks},
                        doi={10.1109/IGARSS.2019.8900250},
                        ISSN={2153-6996},
                        month={July},}

                      </pre>

                  </div>
              </div>

              <div class="paper" id="igarss19-2">
                  <span id="paperImg"><img src="assets/igarss-2019-2.png" width="200px" height="130px" style="border:1px solid #000;"/></span>
                  <div id="pText">
                      <div id="pTitle">A Semantic Framework for Spatial Query Reformulation for Disaster Monitoring Applications </div>
                      <div id="authors">Kuldeep Kurte, <b>Abhishek Potnis</b>, Surya Durbha, Rajat Shinde</div>
                      <div id="conference">IEEE International Geoscience and Remote Sensing Symposium (IGARSS 2019), Japan</div>
                      <div id="sharePaper"><a href="javascript:toggleblock('igarss19-2-abs')">abstract</a> | <a target="_blank" href="https://ieeexplore.ieee.org/abstract/document/8898986">paper</a>  | <a shape="rect" href="javascript:togglebib('igarss19-2')" class="togglebib">bibtex</a></div>
                      <div id="igarss19-2-abs" class="abstract">In disasters, since time is of the essence, quick decision making based on actionable insights is desired. In our earlier work, we have demonstrated that the spatial relationships-based queries can play a vital role in the disaster response phase. However, we found that the utilization of spatial relationships rules (i.e. encoded spatial knowledge) via rule reasoning process do not scale well with the increased number of image regions. Most of the available Resource Description Framework (RDF) triplestores do not support rule reasoning due to the computational complexity and undecidable nature of the rule reasoning process. In this paper, we propose an alternative approach for utilizing spatial knowledge encoded in the form of spatial relationship rules. The proposed approach reformulates the spatial query by expanding it with the configuration encoded in the corresponding spatial relationship rule. The preliminary results are promising and show the applicability of the proposed approach during the time critical events such as flood disaster.</div>
                      <pre xml:space="preserve">
                        @INPROCEEDINGS{8898986,
 author={K. R. {Kurte} and A. V. {Potnis} and S. S. {Durbha} and R. C. {Shinde}},
 booktitle={IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium},
 title={Semantic Framework for Spatial Query Reformulation for Disaster Monitoring Applications},
 year={2019},
 volume={},
 number={},
 pages={9946-9949},
 keywords={Spatial relations;Query reformulation;SPARQL;RDF;SWRL;Linked data;Disaster response},
 doi={10.1109/IGARSS.2019.8898986},
 ISSN={2153-6996},
 month={July},}
                     </pre>


                  </div>
              </div>
<br>
              <div class="paper" id="igarss19-3">
                  <span id="paperImg"><img src="assets/igarss-2019-3.png" width="200px"height="100px" style="border:1px solid #000;" /></span>
                  <div id="pText">
                      <div id="pTitle">Compressive Sensing based Reconstruction and Classification of VHR Disaster Satellite Imagery Using Deep Learning</i> </div>
                      <div id="authors"> Rajat Shinde, <b>Abhishek Potnis</b>, Surya Durbha, Prakash Andugula</div>
                      <div id="conference">IEEE International Geoscience and Remote Sensing Symposium (IGARSS 2019), Japan</div>
                      <div id="sharePaper"><a href="javascript:toggleblock('igarss19-3-abs')">abstract</a> | <a target="_blank" href="https://ieeexplore.ieee.org/abstract/document/8899871">paper</a> | <a shape="rect" href="javascript:togglebib('igarss19-3')" class="togglebib">bibtex</a></div>
                      <div id="igarss19-3-abs" class="abstract">Disasters such as earthquakes, floods, landslides etc. create great economic and social loss by destroying the balance of life and property and create chaos. In the wake of a disaster, it becomes very significant to take real-time and on-the-fly actions to minimize the effects of the event. Remote Sensing data acquired through airborne or spaceborne platforms is usually huge in size and requires huge time in generating actionable insights during the disaster scenario. In this work, we propose a two-fold analysis of the Very High Resolution (VHR) satellite imagery based on Compressive Sensing (CS) and Deep Learning. We propose employing a deep learning approach for inferencing over compressed sensing satellite imagery. We hypothesize that this could be beneficial in generating real-time actionable insights during a catastrophe. In our work, we are using the satellite imagery from GeoEye-1 of Haiti Earthquake. Our objectives are: (1) To generate CS images for 75%, 50%, and, 25% sampling on the sparse space and (2) To develop a deep learning pixel-level classification model based on the UNet architecture using the original and reconstructed images. The UNet architecture has shown promising results for pixel-level classification in the recent literature. We envisage to combine both the objectives into an end-to-end learning framework for on-board processing which we foresee would be of great significance in various applications for rapid disaster management response.</div>

                      <pre xml:space="preserve">
                        @INPROCEEDINGS{8899871,
                    author={R. C. {Shinde} and A. V. {Potnis} and S. S. {Durbha} and P. {Andugula}},
                    booktitle={IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium},
                    title={Compressive Sensing Based Reconstruction and Pixel-Level Classification of Very High-Resolution Disaster Satellite Imagery Using Deep Learning},
                    year={2019},
                    volume={},
                    number={},
                    pages={2639-2642},
                    keywords={Compressed Sensing;Earthquake Disaster Response;Deep Learning},
                    doi={10.1109/IGARSS.2019.8899871},
                    ISSN={2153-6996},
                    month={July},}


                      </pre>


                  </div>
              </div>

                            <div class="paper" id="igarss19-4">
                                <span id="paperImg"><img src="assets/igarss-2019-4.png" width="200px"height="100px" style="border:1px solid #000;" /></span>
                                <div id="pText">
                                    <div id="pTitle">Rapid Earthquake Damage Detection using Deep Learning from VHR Remote Sensing Images</div>
                                    <div id="authors"> Ujwala Bhangale, Surya Durbha, <b>Abhishek Potnis</b>, Rajat Shinde</div>
                                    <div id="conference">IEEE International Geoscience and Remote Sensing Symposium (IGARSS 2019), Japan</div>
                                    <div id="sharePaper"><a href="javascript:toggleblock('igarss19-4-abs')">abstract</a> | <a target="_blank" href="https://ieeexplore.ieee.org/abstract/document/8898147">paper</a> | <a shape="rect" href="javascript:togglebib('igarss19-4')" class="togglebib">bibtex</a></div>
                                    <div id="igarss19-4-abs" class="abstract">Very High Resolution (VHR) remote sensing optical imagery is a huge source of information that can be utilized for earthquake damage detection and assessment. Time critical task such as performing the damage assessment, providing immediate delivery of relief assistance require immediate response; however, processing voluminous VHR imagery using highly accurate, but computationally expensive deep learning algorithms demands the High Performance Computing (HPC) power. To maximize the accuracy, deep convolution neural network (CNN) model is designed especially for the earthquake damage detection using remote sensing data and implemented using high performance GPU without compromising with the execution time. Geoeye1 VHR disaster images of the Haiti earthquake occurred in year 2010 is used for analysis. Proposed model provides good accuracy for damage detection; also significant execution speed is observed on GPU K80 High Performance Computing (HPC) platform.
</div>
<pre xml:space="preserve">
  @INPROCEEDINGS{8898147,
  author={U. {Bhangale} and S. {Durbha} and A. {Potnis} and R. {Shinde}},
  booktitle={IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium},
  title={Rapid Earthquake Damage Detection Using Deep Learning from VHR Remote Sensing Images},
  year={2019},
  volume={},
  number={},
  pages={2654-2657},
  keywords={Deep learning;Deep CNN;GPU;damage detection;HPC},
  doi={10.1109/IGARSS.2019.8898147},
  ISSN={2153-6996},
  month={July},}



</pre>

                                </div>
                            </div>



                <div class="paper" id="igarss18-1">
                    <span id="paperImg"><img src="assets/rs.png" width="200px" height="120px" style="border:1px solid #000;"/></span>
                    <div id="pText">
                        <div id="pTitle">A Geospatial Ontological Model for Remote Sensing Scene Semantic Knowledge Mining for the Flood Disaster </div>
                        <div id="authors"><b>Abhishek Potnis</b>, Surya Durbha</div>
                        <div id="conference">IEEE International Geoscience and Remote Sensing Symposium (IGARSS 2018), Spain</div>
                        <div id="sharePaper"><a href="javascript:toggleblock('igarss18-1-abs')">abstract</a> | <a target="_blank" href="https://ieeexplore.ieee.org/abstract/document/8517680">paper</a> | <a shape="rect" href="javascript:togglebib('igarss18-1')" class="togglebib">bibtex</a></div>
                        <div id="igarss18-1-abs" class="abstract">Numerous remote sensing applications – flood monitoring, forest fires monitoring, earthquake analysis etc. require users to query satellite images based on their content. Such requirements have led to the evolution of Content-based Image Information Mining Systems over the last decade.
Recent developments in the area of Image Information Mining(IIM) are geared towards bridging the gap between low level image features and higher-level semantics. This research focuses on improving the semantic understanding of a remote sensing scene during the flood disaster from a spatio-contextual standpoint. During a flood occurrence, it is crucial to understand the flood inundation and receding patterns in context to the spatial configurations of the landuse/land-cover in the flooded regions. This study focuses on bridging the spatio-contextual semantic gap in understanding of the remote sensing imagery during a flood, thereby attempting to improve the machine interpretability of a flood remote sensing imagery. In this regard, the Flood Scene Ontology (FSO) has been developed to mine the topological and directional knowledge in context to the flood disaster phenomenon. The FSO is envisaged to form the basis for developing applications that would utilize the spatio-contextual semantics of the flood disaster to aid in the Disaster Assessment and Management process. This paper describes the conceptual framework that was developed to address the same. </div>

<pre xml:space="preserve">
@INPROCEEDINGS{8517680,
author={A. V. Potnis and S. S. Durbha and K. R. Kurte},
booktitle={IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium},
title={A Geospatial Ontological Model for Remote Sensing Scene Semantic Knowledge Mining for the Flood Disaster},
year={2018},
volume={},
number={},
pages={5274-5277},
keywords={content-based retrieval;data mining;disasters;fires;floods;geographic information systems;geophysical image processing;hydrological techniques;image retrieval;ontologies (artificial intelligence);remote sensing;flood scene ontology;remote sensing scene semantic knowledge mining;content-based image information mining systems;IIM;numerous remote sensing applications;low level image features;satellite images;forest fires monitoring;geospatial ontological model;spatio-contextual semantics;flood disaster phenomenon;flood remote sensing imagery;spatio-contextual semantic gap;flooded regions;flood inundation;flood occurrence;spatio-contextual standpoint;semantic understanding;higher-level semantics;Floods;Remote sensing;Ontologies;Roads;Semantics;Buildings;Resource description framework;geospatial;ontology;contextual;flood;disaster;semantics},
doi={10.1109/IGARSS.2018.8517680},
ISSN={2153-7003},
month={July},}
</pre>




                    </div>
                </div>



                <div class="paper" id="igarss18-2">
                    <span id="paperImg"><img src="assets/jetson-tk1.png" width="200px" height="100px" style="border:1px solid #000;"/><br>Image Source: Nvidia</span>
                    <div id="pText">

                        <div id="pTitle">On-Board Biophysical Parameters Estimation using High Performance Computing </div>
                        <div id="authors">Pratyush Talreja, Surya Durbha, <b>Abhishek Potnis</b></div>
                        <div id="conference">IEEE International Geoscience and Remote Sensing Symposium (IGARSS 2018), Spain</div>
                        <div id="sharePaper"><a href="javascript:toggleblock('igarss18-2-abs')">abstract</a> | <a target="_blank" href="https://ieeexplore.ieee.org/document/8518403">paper</a> | <a shape="rect" href="javascript:togglebib('igarss18-2')" class="togglebib">bibtex</a></div>
                        <div id="igarss18-2-abs" class="abstract">Jetson TK1 is the first mobile processor from NVIDIA having similar features and architecture as that of a modern desktop GPU and still using low power from a mobile chip. Therefore, Jetson TK1 runs the same CUDA code (running on desktop GPU) with similar level of performance. Also, with the dawn of GPU technology, it has become possible to perform tasks (that are computationally intensive) in realtime or near-real time. In the agricultural domain, retrieving the biophysical parameters of the crop is important as it provides insights into the plant growth status. Inversion of the Radiative Transfer Model enables to obtain these parameters. However, such a process is highly computationally intensive. The focus of this work is to develop and implement an approach that takes the advantage of embedded High-Performance Computing (HPC) capability of Jetson TK1 to significantly improve the inversion process of a Radiative Transfer Model. The experimental results show that Jetson TK1 based biophysical parameters estimation gives significant speedup, which opens-up the possibility of having a Jetson based embedded platform for on-board biophysical parameters estimation in the future. In such a scenario, where there are constraints related to energy and power, Jetson TK1 can become a practicable option by providing a GPU based architecture for running energy-aware computationally intensive algorithms in parallel for processing the data, and generating the results in real-time or near-real time while taking care of the power usage.


                    </div>
                        <pre xml:space="preserve">
@INPROCEEDINGS{8518403,
author={P. V. Talreja and S. S. Durbha and A. V. Potnis},
booktitle={IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium},
title={On-Board Biophysical Parameters Estimation Using High Performance Computing},
year={2018},
volume={},
number={},
pages={5445-5448},
keywords={crops;embedded systems;graphics processing units;parallel architectures;parameter estimation;power aware computing;radiative transfer;embedded platform;highly computationally intensive;plant growth status;agricultural domain;CUDA code;mobile chip;NVIDIA;mobile processor;embedded high-performance computing;radiative transfer model;energy-aware computationally intensive algorithms;GPU based architecture;modern desktop GPU;Jetson TK1;on-board biophysical parameters estimation;Jetson TK1;Biophysical parameters estimation;GPU;HPC;Radiative Transfer Model},
doi={10.1109/IGARSS.2018.8518403},
ISSN={2153-7003},
month={July},}
</pre>

                </div><br>

                <div class="paper" id="igarss17">
                    <span id="paperImg"><img src="assets/dfo.jpg" width="200px"/></span>
                    <div id="pText">

                        <div id="pTitle">A Spatio-Temporal Ontological Model for Flood Disaster Monitoring</div>
                        <div id="authors">Kuldeep Kurte, Surya Durbha, Roger King, Nicolas Younan, <b>Abhishek Potnis</b></div>
                        <div id="conference">IEEE International Geoscience and Remote Sensing Symposium (IGARSS 2017), United States of America</div>
                        <div id="sharePaper"><a href="javascript:toggleblock('igarss17-abs')">abstract</a> | <a target="_blank" href="https://ieeexplore.ieee.org/document/8128176">paper</a> | <a shape="rect" href="javascript:togglebib('igarss17')" class="togglebib">bibtex</a></div>
                        <div id="igarss17-abs" class="abstract">During an extreme event such as flood disaster, it is important to study flood inundation and receding patterns to understand the dynamic spatio-temporal behavior of flood. In addition to the general change detection techniques in RS, a proper conceptualization of `change' during flood disaster is necessary to model its dynamic behavior. This motivated the development of Ontology, which is able to capture the dynamically evolving phenomenon. This Ontology is envisaged as a precursor for developing applications that integrate the spatio-temporal dimensions of a dynamically evolving system such as floods. This paper describes the conceptual framework that was developed to address the same.
                        </div>
                        <pre xml:space="preserve">
@INPROCEEDINGS{8128176,
author={K. R. Kurte and S. S. Durbha and R. L. King and N. H. Younan and A. V. Potnis},
booktitle={2017 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)},
title={A spatio-temporal ontological model for flood disaster monitoring},
year={2017},
volume={},
number={},
pages={5213-5216},
keywords={disasters;emergency management;floods;hydrological techniques;ontologies (artificial intelligence);spatiotemporal phenomena;Ontology;dynamically evolving system;flood disaster monitoring;flood dynamic spatio-temporal behavior;flood inundation;general change detection techniques;spatio-temporal dimensions;spatio-temporal ontological model;Buildings;Floods;Geospatial analysis;OWL;Ontologies;Roads;Semantics;4D-fluent;Ontology;Spatio-Temporal},
doi={10.1109/IGARSS.2017.8128176},
ISSN={},
month={July},}
}</pre>
                    </div>
                </div>

                <div class="paper" id="voila-iswc16">
                    <span id="paperImg"><img src="assets/voila.png" width="200px" height="150px" style="border:1px solid #000;"/></span>

                    <div id="pText">

                        <div id="pTitle">Exploring Visualization of Geospatial Ontologies Using Cesium. </div>
                        <div id="authors"><b>Abhishek Potnis</b>, Surya Durbha</div>
                        <div id="conference">International Workshop on Visualization and Interaction for Ontologies and Linked Data(VOILA), International Semantic Web Conference (ISWC 2016), Japan</div>
                        <div id="sharePaper"><a href="javascript:toggleblock('voila-iswc16-abs')">abstract</a> | <a target="_blank" href="http://ceur-ws.org/Vol-1704/paper14.pdf">paper</a> | <a shape="rect" href="javascript:togglebib('voila-iswc16')" class="togglebib">bibtex</a> | <a target="_blank" href="http://www.geosysiot.in/tools/geoPoliticalOntoViz/">visual interface developed</a></div>
                        <div id="voila-iswc16-abs" class="abstract">In recent years, there has been a substantial increase in the usage of geospatial data, not only by the scientific community but also by the general public. Considering the diverse and heterogeneous nature of geospatial applications around the world and their inter-dependence, there is an impending need for enabling sharing of semantics of such content-rich geospatial information. Geospatial ontologies form the building blocks for sharing of semantics of this information, thus ensuring interoperability. Visualization of geospatial ontologies from a spatio-temporal perspective can greatly benefit the process of knowledge engineering in the geospatial domain. This paper proposes to visually explore and reason over the instances of a geospatial ontology – the geopolitical ontology developed by the Food and Agriculture Organization of the United Nations using Cesium – a WebGL based virtual globe. It advocates the usage of Cesium for visualization of geospatial ontologies in general by demonstrating visualizations of geospatial data and their relationships.</div>
                        <pre xml:space="preserve">
@inproceedings{DBLP:conf/semweb/PotnisD16,
  author    = {Abhishek Potnis and
               Surya S. Durbha},
  title     = {Exploring Visualization of Geospatial Ontologies using Cesium},
  booktitle = {Proceedings of the Second International Workshop on Visualization
               and Interaction for Ontologies and Linked Data co-located with the
               15th International Semantic Web Conference, VOILA@ISWC 2016, Kobe,
               Japan, October 17, 2016.},
  pages     = {143--150},
  year      = {2016},
  crossref  = {DBLP:conf/semweb/2016voila},
  url       = {http://ceur-ws.org/Vol-1704/paper14.pdf},
  timestamp = {Wed, 12 Oct 2016 15:50:13 +0200},
  biburl    = {https://dblp.org/rec/bib/conf/semweb/PotnisD16},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}</pre>
                    </div>
                </div>


                <div class="paper" id="sssw16">
                    <span id="paperImg"><img src="assets/swe.jpg" width="200px" height="130px" style="border:1px solid #000;"/><br>Image Source: OGC</span>

                    <div id="pText">

                        <div id="pTitle">Poster Presentation: Semantic Mediation and Reasoning on Streaming Sensor Data over Geospatial Sensor Web</div>
                        <div id="authors"><b>Abhishek Potnis</b>, Surya Durbha, </div>
                        <div id="conference">12th Semantic Web Summer School (SSSW 2016), Italy</div>
                    </div>
                </div>


            </div>

            <div class="row" id="teaching">
                <h3>Teaching</h3>
                <div class="col-sm-12" style="font-size:17px;">


                    <div>
                        <ul>
                          <li>Teaching Assistant, <a href="http://www.csre.iitb.ac.in/gnr629.php" target="_blank">GNR 629: Advances in Geospatial Standards, Interoperability and Knowledge Discovery</a></li>

                          <li>Teaching Assistant, <a href="http://www.csre.iitb.ac.in/gnr605.php" target="_blank">GNR 605: Principles of Geographic Information Systems</a></li>
                          <li>Teaching Assistant, <a href="http://www.csre.iitb.ac.in/gnr636.php" target="_blank">GNR 636: Remote Sensing of Vegetation</a></li>

                          <li>Teaching Assistant, <a href="http://www.csre.iitb.ac.in/gnr615.php" target="_blank">GNR 615: Geographic Information Systems Lab</a></li>

                          <li>Teaching Assistant, <a href="http://www.csre.iitb.ac.in/ugMinor.php" target="_blank">GNR 402: Introduction to Geographic Information Systems</a></li>


                        </ul>
                    </div>

                </div>

            </div>



        <!-- Projects -->


        <div class="row" id="projects">
            <h3>Projects</h3>
            <div class="col-sm-12" style="font-size:17px;">

              <div class="project" id="gee-soee">

                  <span id="paperImg"><img src="assets/gee-soee.png" width="200px" height="120px" style="border:1px solid #000;"/></span>

                  <div id="pTitle">Machine Learning based Cropland Mapping in India for Identifying Human-Wildlife Conflict Locations</div>
                  <div id="course"><a href="https://sites.google.com/view/summerofearthengine/home" target="_blank">Google Summer of Earth Engine 2019</a></div>
                    <div id="conference">Mentor: Anubhav Vanamamalai, <a href="https://cwsindia.org/" target="_blank">Centre for Wildlife Studies</a></div>
                  <div id="shareProject"> <a href="javascript:toggleblock('gee-soee-desc')">description</a> | <a href="https://medium.com/google-earth/wrapping-up-the-summer-of-earth-engine-e98a22fabf0d" target="_blank">blog post</a></div><br><br>
                  <div id="gee-soee-desc" class="abstract">
                      Project Description: <br>
                      <ul>
                        <li>Implemented Supervised Satellite Image Classification for identifying different crop types using Google Earth Engine for understanding wildlife conflict</li>
                        <li>Experimented with different classification approaches such as Random Forest, SVM and ANN, to maximize model performance</li>        </ul>
                  </div>
              </div>


              <div class="project" id="gee-buildathon">

                  <span id="paperImg"><img src="assets/gee-buildathon.png" width="200px" style="border:1px solid #000;"/></span>

                  <div id="pTitle">Identifying Solar Farms in India using Machine Learning with Google Earth Engine</div>
                  <div id="course">Google Earth Engine India Advanced Summit Buildathon 2019</div>
                  <div id="shareProject"><a target="_blank" href="https://code.earthengine.google.com/b4f563c2bf05f0a5992a68273e7c4ae0">code</a> | <a href="javascript:toggleblock('gee-buildathon-abs')">description</a> | <a href="https://docs.google.com/presentation/d/1rVrLnrl9H-aglIA4UEr7Ajn249WBWNN2wKxDW25h-MQ/edit" target="_blank">presentation</a> | <a href="https://sites.google.com/view/eeindia-advanced-summit/summit-resources#h.p_xf20uslDUytp" target="_blank">buildathon</a> </div><br><br>
                  <div id="gee-buildathon-abs" class="abstract">
                      Project Description: <br>
                      <ul>
                        <li>Worked in a team of 6, to solve the Binary Classification problem of detecting solar farms in India</li>
                        <li>Employed the Random Forest Classifier with R,G,B, NIR and VV Polarization as features to obtain an Accuracy of 81.07%</li>
<li>Added Wavelet Kernel-based Convolution as an additional feature to detect solar panels' texture thus improving the Accuracy to 83.65%</li>        </ul>
                  </div>
              </div>


              <div class="project" id="asip">

                  <span id="paperImg"><img src="assets/asip.png" width="200px" style="border:1px solid #000;"/></span>

                  <div id="pTitle">Pixel Purity Index and Spectral Angle Based Satellite Image Classifier</div>
                  <div id="course">Advanced Satellite Image Processing Course Project</div>
                  <div id="shareProject"><a target="_blank" href="https://github.com/abhishekvp/PPIbasedSatImgClassifier">code</a> | <a href="javascript:toggleblock('asip-abs')">description</a> </div><br><br><br>
                  <div id="asip-abs" class="abstract">
                      Project Description: <br>
                      <ul>
                          <li>Studied and implemented End Member Extraction using Pixel Purity Index and Spectral Angle to develop a Classifier for classifying satellite imagery into land use land cover classes.</li>
                          <li>Developed an interactive web application to upload a satellite image and perform image classification</li>
                      </ul>
                  </div>
              </div>

              <div class="project" id="gis">

                  <span id="paperImg"><img src="assets/gis.png" width="200px" style="border:1px solid #000;"/></span>

                  <div id="pTitle">Emergency Response Route Navigation and Simulation of Bus Service in IIT Bombay Campus</div>
                  <div id="course">Geographic Information Systems Course Project</div>
                  <div id="shareProject"><a target="_blank" href="https://github.com/abhishekvp/miniBusEmergencyRouteSimulator">code</a> | <a href="javascript:toggleblock('gis-abs')">description</a> </div><br><br><br>
                  <div id="gis-abs" class="abstract">
                      Project Description: <br>
                      <ul>
                          <li>Implemented a route navigation feature using PgRouting, that would identify the nearest bus from an emergency location and guide it using the shortest possible route computed using the Dijkstra's algorithm, displaying the time to reach the location</li>
                          <li>Developed an interactive web application that simulated the mini-bus service in the campus</li>
                      </ul>
                  </div>
              </div>


              <div class="project" id="sip">

                  <span id="paperImg"><img src="assets/sip.png" width="200px" style="border:1px solid #000;"/></span>

                  <div id="pTitle">Satellite Image Classifier using Parallelepiped Classification</div>
                  <div id="course">Satellite Image Processing Course Project</div>
                  <div id="shareProject"><a target="_blank" href="https://github.com/abhishekvp/parallelepipedClassifier">code</a> | <a href="javascript:toggleblock('sip-abs')">description</a> </div><br><br><br>
                  <div id="sip-abs" class="abstract">
                      Project Description: <br>
                      <ul>
                          <li>Studied and implemented the pixel based Parallelepiped Classifier for classifying satellite imagery into land use land cover classes.</li>
                          <li>Developed an interactive web application for training the classifier to generate a model and perform satellite image classification</li>
                      </ul>
                  </div>
              </div>


                <div class="project" id="data-interop">

                    <span id="paperImg"><img src="assets/wms.png" width="200px" style="border:1px solid #000;"/><br>Image Source: OpenGeo</span>

                    <div id="pTitle">An Integrated Client-Server based Interoperable Geographic Information System for Forest Fire Monitoring</div>
                    <div id="course">Geospatial Data Interoperability Course Project</div>
                    <div id="shareProject"><a target="_blank" href="https://github.com/abhishekvp/Spatial-Data-Interoperability">code</a> | <a href="javascript:toggleblock('data-interop-abs')">description</a> </div><br><br><br>
                    <div id="data-interop-abs" class="abstract">
                        Project Description: <br>
                        <ul>
                            <li>Developed an AJAX driven interactive web client aimed at integrating and querying Geospatial Web Services using Geoserver and Google Web Toolkit</li>
                            <li>Integrated services such as Web Feature Service(WFS), Web Map Service(WMS), Web Coverage Service(WCS) and Sensor Observation Service(SOS) to form a web mash-up</li>
                        </ul>
                    </div>
                </div>

                                <div class="project" id="pothole">

                    <span id="paperImg"><img src="assets/pothole.png" width="200px" style="border:1px solid #000;"/></span>

                    <div id="pTitle">Route Navigation and Pothole Monitoring using Crowd Sourced Pothole Mapping</div>
                    <div id="course"> This application won the Esri India's mApp Your Way App Development Challenge 2015</div>
                                    <div id="shareProject"> <a href="javascript:toggleblock('pothole-abs')">description</a> | <a target="_blank" href="http://www.csre.iitb.ac.in/esriAppChallenge.php">article</a> | <a target="_blank" href="http://www.esriindia.com/~/media/esri-india/files/pdfs/appchallenge/winner-team_2015.pdf">slides</a></div><br><br><br>
                    <div id="pothole-abs" class="abstract">
                        Project Description: <br>
                        <ul>
                            <li>Developed a GIS based Android and web application to address the issue of monitoring and managing potholes on Indian roads</li>
                            <li>Intelligent pothole-free routing for senior citizens, pregnant women and patients</li>

                        </ul>
                    </div>
                </div><br><br>

                <h3>Open Source Contributions</h3>

                <div class="project" id="gsoc16">

                    <span id="paperImg"><img src="assets/gsoc16.jpg" width="200px" style="border:1px solid #000;"/></span>

                    <div id="pTitle">Google Summer of Code 2016 - Enabling Cesium for Liquid Galaxy</div>
                    <div id="course">Liquid Galaxy</div>
                    <div id="conference">Mentor: Andrew Leahy, Western Sydney University</div>
                    <div id="shareProject"><a target="_blank" href="https://github.com/abhishekvp/cesium-lg">code</a> | <a href="javascript:toggleblock('gsoc16-abs')">description</a> | <a href="https://cesiumjs.org/demos/LiquidGalaxy/" target="_blank">blog post</a> </div><br><br><br>
                    <div id="gsoc16-abs" class="abstract">
                        Project Description: <br>
                        <ul>
                            <li>Developed a Proof of Concept Prototype application that enabled Cesium - an open source virtual globe to run across the multiple displays, providing an immersible and a riveting experience to the users</li>
                            <li>Focused on endowing Cesium with features such as Camera Synchronization, Content Synchronization across the displays and Space Navigation Camera Control.</li>
                        </ul>
                    </div>
                </div>

                <div class="project" id="gsoc15">

                    <span id="paperImg"><img src="assets/gsoc15.jpg" width="200px" style="border:1px solid #000;"/></span>

                    <div id="pTitle">Google Summer of Code 2015 - NASA’s Data Curtains from Space</div>
                    <div id="course">Cesium Community</div>
                    <div id="conference">Mentors: Mike McGann, Ryan Boller, NASA</div>
                    <div id="shareProject"><a target="_blank" href="https://github.com/nasa-gibs/data-curtains/">code</a> | <a href="javascript:toggleblock('gsoc15-abs')">description</a> | <a href="https://cesiumjs.org/demos/DataCurtains/" target="_blank">blog post</a> </div><br><br><br>
                    <div id="gsoc15-abs" class="abstract">
                        Project Description: <br>
                        <ul>
                            <li>Developed a web application to visualize LiDAR Profiles captured by the CALIPSO Satellite with the orbital tracks of the satellite and Aqua-MODIS-Reflectance as the base layer, using CesiumJS Library.</li>
                            <li>Proposed and implemented the structure of meta-data in .json format to be generated from .hdf files</li>
                            <li>Implemented scripts to extract imagery and meta-data from .hdf files, to be consumed by the web app</li>
                        </ul>
                    </div>
                </div>

                <div class="project" id="mozilla">

                    <span id="paperImg"><img src="assets/firefox.jpg" width="200px" style="border:1px solid #000;"/><br>Image Source: Mozilla</span>

                    <div id="pTitle">Mozilla Firefox | Open Source Code Contributions</div>
                    <div id="shareProject"><a target="_blank" href="https://hg.mozilla.org/mozilla-central/log?rev=Abhishek+Potnis">code</a> | <a href="javascript:toggleblock('mozilla-abs')">description</a> </div><br><br><br><br><br>
                    <div id="mozilla-abs" class="abstract">
                        Contributions Description: <br>
                        <ul>
                            <li>Fixed bugs by authoring code patches primarily in JavaScript for Mozilla Firefox</li>
                            <li>Edited and improved technical articles on Mozilla Developer Network</li>
                            <li>Recognized as a core contributor in the “about:credits” section of Mozilla Firefox</li>
                            <li>Invited to attend the Mozilla Summit 2013 at Santa Clara, USA</li>
                        </ul>
                    </div>
                </div>




            </div>


        </div>

        <div class="row" id="acads">
            <h3>Academics</h3>
            <div class="col-sm-12" style="font-size:17px;">


                <div class="project" id="mtech-phd">
                    <br>
                    <span id="paperImg"><img src="assets/degree.png" width="200px" /></span>

                    <div id="pTitle">M.Tech. - Ph.D. Dual Degree [2014 - 2021]<br><b>Indian Institute of Technology Bombay</b>, India</div>
                    <div id="course"><b>Specialization:</b> Geoinformatics</div>
                    <div id="authors">CPI: 9.28</div>

                </div><br><br><br><br>

                <div class="project" id="be">

                    <span id="paperImg"><img src="assets/degree.png" width="200px" /></span>

                    <div id="pTitle">Bachelors of Engineering [2009 - 2013]<br>Vidyavardhini's College of Engg. and Tech., University of Mumbai, India</div>
                    <div id="course"><b>Specialization:</b> Computer Engineering</div>
                    <div id="authors">Percentage: 74.26</div>

                </div>

            </div>
        </div>


 <div class="row" id="myTalks">
  <div class="col-sm-12" >

      <h3>Talks</h3>
   
      <div id="carouselExampleControls" class="carousel slide" data-ride="carousel">
        <div class="carousel-inner">
          <div class="carousel-item active">
            <div class="cards-wrapper">

              <div class="card">
                <img src="./assets/panel.jpeg" class="card-img-top" alt="...">
                <div class="card-body">
                  <h5 class="card-title">Panel Discussion at IEEE HKN TechX Conference</h5>
                  <p class="card-text">Participated with esteemed researchers in a panel on AI Beyond the Engineering</p>
                  <a href="#" target="_blank" class="btn btn-primary">Recording Coming Soon</a>
                </div>
              </div>

            <div class="card">
              <img src="./assets/talk1.png" class="card-img-top" alt="...">
              <div class="card-body">
                <h5 class="card-title">Google's Geo For Good Summit - Lightning Talk</h5>
                <p class="card-text">Mapping of Urban Floods from Remote Sensing Scenes using Google Earth Engine</p>
                <a href="https://www.youtube.com/watch?v=1tx5HbttnwQ" target="_blank" class="btn btn-primary">Watch on YouTube</a>
              </div>
            </div>
            <div class="card">
              <img src="./assets/talk2.png" class="card-img-top" alt="...">
              <div class="card-body">
                <h5 class="card-title">Invited Talk at Vidyavardhini's College of Engg. and Tech., Mumbai</h5>
                <p class="card-text">Deep Learning: An Application Perspective Lecture</p>
                <a href="https://www.youtube.com/watch?v=xHFuCqJeyPE" target="_blank" class="btn btn-primary">Watch on YouTube</a>
              </div>
            </div>

   
     
          </div>
          </div>
          <div class="carousel-item">
            <div class="cards-wrapper">
              <div class="card">
                <img src="./assets/talk3.png" class="card-img-top" alt="...">
                <div class="card-body">
                  <h5 class="card-title">Invited Talk (Distinguished Lecture Series) at CropIn Technologies</h5>
                  <p class="card-text">Knowledge Graphs driven Remote Sensing Scene Understanding</p>
                  <a href="https://www.youtube.com/watch?v=sPBeX1ksZG0" target="_blank" class="btn btn-primary">Watch on YouTube</a>
                </div>
              </div>
              <div class="card">
                <img src="./assets/talk4.png" class="card-img-top" alt="...">
                <div class="card-body">
                  <h5 class="card-title">Google Earth Engine India - Community On Air Showcase</h5>
                  <p class="card-text">Flood Inundation Mapping with Google Earth Engine </p>
                  <a href="https://www.youtube.com/watch?v=10HDdDIQQN0" target="_blank" class="btn btn-primary">Watch on YouTube</a>
                </div>
              </div>
              <div class="card">
                <img src="./assets/talk5.png" class="card-img-top" alt="...">
                <div class="card-body">
                  <h5 class="card-title">Google Summer of Code (GSoC) with Cesium</h5>
                  <p class="card-text">Interactive Visualization of LiDAR profiles from CALIPSO satellite</p>
                  <a href="https://www.youtube.com/watch?v=72mUEVYizvU" target="_blank" class="btn btn-primary">Watch on YouTube</a>
                </div>
              </div>
         
            </div>
          </div>
          <div class="carousel-item">
            <div class="cards-wrapper">

              <div class="card">
                <img src="./assets/talk6.png" class="card-img-top" alt="...">
                <div class="card-body">
                  <h5 class="card-title">News Coverage in Marathi - TechFest, IIT Bombay</h5>
                  <p class="card-text">Demonstration of Pothole Mapping Application for citizens and municipal authorities </p>
                  <a href="https://www.youtube.com/watch?v=72mUEVYizvU" target="_blank" class="btn btn-primary">Watch on YouTube</a>
                </div>
              </div>

              <div class="card">
                <img src="./assets/talk7.png" class="card-img-top" alt="...">
                <div class="card-body">
                  <h5 class="card-title">News Coverage in Marathi: SenseQube - Towards Precision Farming</h5>
                  <p class="card-text">Demonstration of SenseQube - An IoT Platform for Smart Agriculture </p>
                  <a href="https://www.youtube.com/watch?v=yKlFULyEqcI" target="_blank" class="btn btn-primary">Watch on YouTube</a>
                </div>
              </div>
              <div class="card">
                <img src="./assets/talk8.png" class="card-img-top" alt="...">
                <div class="card-body">
                  <h5 class="card-title">News Coverage in Marathi: Pratham - IIT Bombay Student Satellite</h5>
                  <p class="card-text">Launch of Pratham - the first Student Satellite of IIT Bombay</p>
                  <a href="https://youtu.be/dGOpW78veOo?t=374" target="_blank" class="btn btn-primary">Watch on YouTube</a>
                </div>
              </div>
        
            </div>
          </div>
        </div>
        <a class="carousel-control-prev" href="#carouselExampleControls" role="button" data-slide="prev">
          <span class="carousel-control-prev-icon" aria-hidden="true"></span>
          <span class="sr-only">Previous</span>
        </a>
        <a class="carousel-control-next" href="#carouselExampleControls" role="button" data-slide="next">
          <span class="carousel-control-next-icon" aria-hidden="true"></span>
          <span class="sr-only">Next</span>
        </a>
      </div>
</div>

</div>
 
      
   




   

      
      





        <div class="row" id="achievements">
            <h3>Achievements and Awards</h3>
            <div class="col-sm-12" style="font-size:17px;">


                <div>
                    <ul>
                      <li>Recipient of the Academic Research Credits Grant under the framework of Google Cloud Platform Research Credits Programme </li>
                      <li>Invited to attend the Geo for Good Summit at Google, Sunnyvale, CA, USA in Sep. 2019</li>
                      <li>Successfully completed the project "Machine Learning based Mapping of Croplands with Google Earth Engine for Identifying Human-Wildlife Conflict Locations" with <a href="https://cwsindia.org/" target="_blank"> Centre for Wildlife Studies</a> for the <a href="https://sites.google.com/view/summerofearthengine/home?authuser=0" target="_blank">Google Summer of Earth Engine</a> Research Program</li>
                      <li>Winner of Google Earth Engine India Advanced Summit Buildathon 2019 for the project - "Identifying Solar Farms in India using Machine Learning with Google Earth Engine"</li>
                      <li>Finalist in the Google Earth Engine India Challenge 2018 </li>
			<li>Recipient of the IEEE Geoscience and Remote Sensing Society Travel Grant to present at IEEE Geoscience and
Remote Sensing Symposium (IGARSS) 2018, Spain</li>
                        <li>Quarter-Finalist for the India Innovation Challenge 2017 hosted by IIM Bangalore and conducted by Government of India and Texas Instruments</li>
                        <li>Recipient of the International Semantic Web Conference 2016 Student Travel Grant funded by Semantic Web Science Association (SWSA) and the US National Science Foundation (NSF) to present at ISWC 2016 at Kobe, Japan</li>
                        <li>Recipient of the Ministry of Human Resource Development, Govt. of India Fellowship for Ph.D. students</li>
			<li>Official Mozilla Representative [2013 - 2015]</li>
                        <li>Name listed as a Core Contributor on the Mozilla Monument, outside Mozilla’s office space at San Francisco, CA, USA</li>
                        <li>Successfully completed Google Summer of Code 2016</li>
                        <li>Successfully completed Google Summer of Code 2015</li>
                        <li>Represented IIT Bombay for the SAP InnoJAM Challenge 2016 held at SAP Labs, Bangalore</li>
                        <li>Winner of the Esri India's mApp Your Way 2015 - A National Level App Development Challenge for the application – 'Route Navigation and Pothole Monitoring using Crowd Sourced Pothole Mapping'</li>
                        <li>Successfully completed Module 1 of French Language Course conducted by International Relations Office, IIT Bombay, in association with Embassy of France, New Delhi</li>
                        <li>Invited as a Contributor to attend the Mozilla Summit 2013 in Santa Clara, USA</li>
                    </ul>
                </div>

                <h3>Certifications</h3>
                <div>
                    <ul>
                      <li><a href="https://www.coursera.org/account/accomplishments/verify/Z2EFGJTBJ2TJ" target="_blank">Natural Language Processing in TensorFlow</a>  [January 2020]</li>
                      <li><a href="https://www.coursera.org/account/accomplishments/verify/ESWQ39RU5M6N" target="_blank">Convolutional Neural Networks in TensorFlow</a>  [January 2020]</li>
                      <li><a href="https://www.coursera.org/account/accomplishments/verify/JABS6YMRXK3K" target="_blank">Introduction to TensorFlow for Artificial Intelligence, Machine Learning, and Deep Learning</a>  [December 2019]</li>
                        <ul>
                          <li>Instructor: Laurence Moroney, Google</li>
                        </ul>


                        <li><a href="https://www.coursera.org/account/accomplishments/specialization/VJZDRUE396WM" target="_blank">Deep Learning Specialization</a>  [April 2019]</li>

                          <ul>
                            <li>Instructor: Dr. Andrew Ng, Coursera</li>
                          </ul>
                          <li>Oracle Certified Professional Java Programmer SE - 6 [July 2012]</li>
                          <ul>
                            <li>Secured 96% in the OCJP SE-6 Certification Examination</li>
                          </ul>
                    </ul>
                </div>


                                <h3>Synergistic Activities</h3>
                                <div>
                                    <ul>
                                        <li>Manuscript Reviewer</li>

                                          <ul>
                                            <li><a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=4609443" target="_blank">IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing</a></li>
                                            <li><a href="https://www.journals.elsevier.com/international-journal-of-applied-earth-observation-and-geoinformation" target="_blank">International Journal of Applied Earth Observation and Geoinformation</a></li>
                                            <li><a href="https://link.springer.com/journal/12145" target="_blank">Earth Science Informatics, Springer</a></li>
                                            <li><a href="https://www.springer.com/journal/12524/" target="_blank">Journal of the Indian Society of Remote Sensing, Springer</a></li>
                                            <li><a href="https://joss.theoj.org/" target="_blank">Journal of Open Source Software</a></li>
                                            <li><a href="https://drive.google.com/file/d/1RZeh5typAuHnwOjDRNfz7ovkRDtXX-uS/view?usp=sharing" target="_blank">IEEE International Conference on Communication Information and Computing Technology 2021 (ICCICT-2021)</a></li>

                                          </ul>

                                    </ul>
                                    <ul>

                                        <li>Program Committee Member</li>

                                          <ul>
                                            <li><a href="https://webnlg-challenge.loria.fr/workshop_2020/#program" target="_blank">WebNLG+</a> Workshop, <a href="https://www.inlg2020.org" target="_blank"> International Conference on Natural Language Generation (INLG 2020)</a></li>

                                          </ul>
                                      </ul>
                                      <ul>
                                    <li>Session Manager</li>

                                      <ul>
                                        <li><a href="https://www.ingarss2020.org" target="_blank">IEEE International India Geoscience and Remote Sensing Symposium 2020</a></li>
                                        <li><a href="https://igarss2020.org/" target="_blank">IEEE International Geoscience and Remote Sensing Symposium 2020</a></li>

                                      </ul>

                                </ul>
                                </div>

                                <h3>Professional Memberships</h3>
                                <div>
                                    <ul>
                                        <li>IEEE Student Member</li>
                                        <li>IEEE Geoscience and Remote Sensing Society (GRSS) Student Member</li>
                                        <li>Student Member of Resources Engineers Association (REA), CSRE, IIT Bombay</li>
                                    </ul>
                                </div>

                <h3>Selected Invited Talks</h3>
                <div>
                    <ul>
                      <li>Delivered <a href="https://youtu.be/1tx5HbttnwQ?t=62" target="_blank">Lightning Talk</a> at Google's Geo For Good Summit 2020 on "Machine Learning based Multi-Class Segmentation of Urban Flood Remote Sensing Scenes with Google Earth Engine"</li>
                      <li>Delivered <a href="https://sites.google.com/earthoutreach.org/geoforgood19/agenda/partner-panels?authuser=0#h.p_-gyons_mQ7ZX">Talk</a> on "Machine Learning based Mapping of Croplands with Google Earth Engine" in Partner Panel at Google's Geo For Good Summit 2019</li>
                      <li>Delivered <a href="https://docs.google.com/presentation/d/1fRAg7Kom8_kLNB4MfLKGYCDtqdt19PNgnAt5fcQNqAk/edit#slide=id.p" target="_blank">Session</a> on "Google Earth Engine and TensorFlow" at the Google Earth Engine Student Summit 2019 at IIT Bombay</li>
                      <li>Delivered <a href="https://youtu.be/xUiE5tLkXhk?t=140" target="_blank">Talk</a> on "Flood Mapping with Google Earth Engine" at the <a href="https://www.youtube.com/watch?v=xUiE5tLkXhk" target="_blank">Community on Air Webinar</a> organized by the Google Earth Engine India Community. </li>
                      <li>Delivered Talk on "Role of Deep Learning in Disaster Monitoring" at the <a href="https://datahack.analyticsvidhya.com/contest/the-convergence-of-big-data-and-machine-learning-m/" target="_blank">Intel AI Meetup</a>, Mumbai</li>
                      <li>Conducted a <a href="https://cerg.org.in/past-events" target="_blank">two-day workshop</a> on QGIS with Dr. Kuldeep Kurte for the Geology Community as a part of the GeoWeek of October 2017, held at Fergusan College, Pune in Maharashtra, India</li>
                      <li>Delivered Talks on Preparing for Google Summer of Code for students at CSRE,IIT Bombay in January 2017 and January 2018</li>
                      <li>Delivered <a href="http://abhishekvp.github.io/blog/2014/10/09/mozilla-event-at-isaac-2014-technical.html" target="_blank">Talk</a> on Getting Involved in Open Source - Contributing to Mozilla at the ISAAC 2014, the Technical Festival of Thadomal Shahani College of Engineering(TSEC), Mumbai in October 2014</li>
                      <li>Delivered <a href="http://abhishekvp.github.io/blog/2013/06/03/moztalk-at-iit-bombay-2/" target="_blank">Talk</a> on Contributing to Open Source at IIT Bombay as a part of the MozTalk conducted by Web and Coding Club, IIT Bombay in June 2013</li>
                    </ul>
                </div>

                <h3>Summer School and Tutorials Attended</h3>
                <div>
                    <ul>
                        <li>The <a href="https://sssw.org/2016/" target="_blank">12th Semantic Web Summer School (SSSW 2016)</a>, 17th - 23rd July, 2016. University Residential Center , Bertinoro, Bologna, Italy</li>
                          <li><a href="http://voila2016.visualdataweb.org/" target="_blank">Visualization and Interaction for Ontologies and Linked Data<a>, 2nd International Workshop co-located with International Semantic Web Conference 2016, October 17, 2016, Kobe, Japan</li>
                        <li><a href="https://semantic-web-of-things.appspot.com/?p=ISWC2016Tutorial" target="_blank">Semantic Web of Things</a> Tutorial by co-located with International Semantic Web Conference 2016, October 17, 2016, Kobe, Japan</li>

                    </ul>
                </div>



            </div>

        </div>
    </div>
    <div class="footer bg-light"><br>
        <p>Made with <span style="color: #e25555;">&#9829;</span> using <a href="http://getbootstrap.com/" target="_blank">Bootstrap</a> and <a href="https://jonbarron.info/" target="_blank">this</a>.</p>
    </div>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.7.0/jquery.min.js"></script>

   <!--<script src="https://cdnjs.cloudflare.com/ajax/libs/bootstrap/5.2.1/js/bootstrap.min.js"></script>-->
    <script>
        hideallbibs();
        hideblock('jp-01-abs');
        hideblock('jp-02-abs');
        hideblock('igarss-2021-1-abs');
        hideblock('igarss-2021-2-abs');
        hideblock('igarss-2021-3-abs');
        hideblock('igarss-2020-1-abs');
        hideblock('igarss-2020-2-abs');
        hideblock('acm-sigspatial-1-abs');
        hideblock('igarss19-1-abs');
        hideblock('igarss19-2-abs');
        hideblock('igarss19-3-abs');
        hideblock('igarss19-4-abs');

        hideblock('igarss18-1-abs');
        hideblock('igarss18-2-abs');

        hideblock('igarss17-abs');
        hideblock('voila-iswc16-abs');
        hideblock('data-interop-abs');

        hideblock('gee-soee-desc');
        hideblock('gee-buildathon-abs');

        hideblock('asip-abs');
        hideblock('sip-abs');
        hideblock('gis-abs');
        hideblock('gsoc15-abs');
        hideblock('gsoc16-abs');
        hideblock('mozilla-abs');
        hideblock('pothole-abs');

        //hideblock('pratham-abs');

        // handle links with @href started with '#' only
        $(document).on('click', 'a[href^="#"]', function(e) {
            // target element id
            var id = $(this).attr('href');
            console.log(id);
            if(id == "#carouselExampleControls"){
              return;
            }
            // target element
            var $id = $(id);
            if ($id.length === 0) {
                return;
            }

            // prevent standard hash navigation (avoid blinking in IE)
            e.preventDefault();

            // top position relative to the document
            var pos = $id.offset().top;

            // animated top scrolling
            $('body, html').animate({
                scrollTop: pos-20
            });

        });

        function init() {
          document.getElementById("aboutInit").click();
          console.log("Clicked");
          $("img").on("contextmenu",function(e){return false;});
          $('img').on('dragstart', function () {
              console.log("drag");
               return false;
           });
        }
        
        function toggleOlderNews() {
        $("#olderNewsListItems").toggle();
        }
  </script>
    <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-55373896-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-55373896-1');
</script>


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.3.1/dist/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
<script src="https://cdn.jsdelivr.net/npm/popper.js@1.14.7/dist/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@4.3.1/dist/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>



</body>

</html>
